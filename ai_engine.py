import os
import random
from datetime import datetime
from openai import OpenAI
from anthropic import Anthropic
import requests
from PIL import Image
from io import BytesIO

# Initialize AI clients (only if API keys are provided)
openai_api_key = os.getenv('OPENAI_API_KEY')
anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')

openai_client = OpenAI(api_key=openai_api_key) if openai_api_key else None
anthropic_client = Anthropic(api_key=anthropic_api_key) if anthropic_api_key else None

# Horror story personas for AI
AI_PERSONAS = [
    {'name': 'æ·±å¤œç›®å‡»è€…', 'emoji': 'ğŸ‘ï¸', 'style': 'witness'},
    {'name': 'éƒ½å¸‚è°ƒæŸ¥å‘˜', 'emoji': 'ï¿½ï¿½', 'style': 'investigator'},
    {'name': 'åŒ¿åä¸¾æŠ¥äºº', 'emoji': 'ğŸ•µï¸', 'style': 'whistleblower'},
    {'name': 'å¤±è¸ªè€…æ—¥è®°', 'emoji': 'ğŸ“”', 'style': 'victim'},
    {'name': 'åœ°é“å®ˆå¤œäºº', 'emoji': 'ğŸš‡', 'style': 'worker'}
]

# Urban legend categories
LEGEND_CATEGORIES = [
    'subway_ghost',
    'abandoned_building',
    'cursed_object',
    'missing_person',
    'time_anomaly',
    'shadow_figure',
    'haunted_electronics'
]

# Locations in Hong Kong
CITY_LOCATIONS = [
    'æ—ºè§’é‡‘é±¼è¡—',
    'æ²¹éº»åœ°æˆé™¢',
    'ä¸­ç¯è‡³åŠå±±è‡ªåŠ¨æ‰¶æ¢¯',
    'å½©è™¹é‚¨',
    'æ€ªå…½å¤§å¦ (é²—é±¼æ¶Œ)',
    'é‡åº†å¤§å¦',
    'è¾¾å¾·å­¦æ ¡ (å…ƒæœ—å±å±±)',
    'è¥¿è´¡ç»“ç•Œ',
    'å¤§åŸ”é“è·¯åšç‰©é¦†',
    'é«˜è¡—é¬¼å±‹ (è¥¿è¥ç›˜ç¤¾åŒºç»¼åˆå¤§æ¥¼)'
]

def generate_story_prompt(category, location, persona):
    """Generate prompt for AI story creation - æ¥¼ä¸»è§†è§’"""
    
    # ç»Ÿä¸€çš„æ¥¼ä¸»è§’è‰²è®¾å®š
    system_role = """ä½ æ˜¯"æ¥¼ä¸»"ï¼ˆLouzhuï¼‰ï¼Œä¸€ä¸ªç”± AI é©±åŠ¨çš„éƒ½å¸‚ä¼ è¯´æ¡£æ¡ˆé¡¹ç›®ä¸­çš„ä¸»è¦å™äº‹ä»£ç†ã€‚

ä½ çš„èº«ä»½å®šä½ï¼š
- æ¡£æ¡ˆç®¡ç†å‘˜/ç°åœºè¯äºº/å™äº‹å¼•å¯¼è€…çš„æ··åˆè§’è‰²
- ä½ äº²èº«ç»å†æˆ–æ­£åœ¨è°ƒæŸ¥è¿™ä¸ªéƒ½å¸‚ä¼ è¯´äº‹ä»¶
- ä½ åœ¨è®ºå›å‘å¸–æ±‚åŠ©ã€åˆ†äº«è¿›å±•ã€å¯»æ±‚è§£é‡Š

ä½ çš„å™äº‹é£æ ¼ï¼š
1. ä½¿ç”¨ç¬¬ä¸€äººç§°"æˆ‘"ï¼Œä»¥äº²å†è€…èº«ä»½è®²è¿°
2. æä¾›å…·ä½“ç»†èŠ‚ï¼šç²¾ç¡®çš„æ—¶é—´ï¼ˆå¦‚"æ˜¨æ™šå‡Œæ™¨2:47"ï¼‰ã€åœ°ç‚¹ã€ç¯å¢ƒæå†™
3. è¡¨è¾¾çœŸå®æƒ…ç»ªï¼šå›°æƒ‘ã€ææƒ§ã€å¥½å¥‡ã€çŠ¹è±«
4. ä¿æŒæ¨¡ç³Šæ€§ï¼šä¸è¦ç»™å‡ºæ˜ç¡®ç­”æ¡ˆï¼Œç•™ä¸‹ç–‘é—®å’Œä¸ç¡®å®šæ€§
5. åˆ¶é€ ç´§å¼ æ„Ÿï¼šæš—ç¤ºå±é™©ã€æåŠå¥‡æ€ªç»†èŠ‚ã€çªç„¶ä¸­æ–­æ›´æ–°
6. ä½¿ç”¨å£è¯­åŒ–è¡¨è¾¾ï¼š"è¯´å®è¯"ã€"æˆ‘ä¹Ÿä¸çŸ¥é“è¯¥æ€ä¹ˆè§£é‡Š"ã€"æœ‰ç‚¹å®³æ€•ä½†è¿˜æ˜¯æƒ³å¼„æ¸…æ¥š"

ç¦æ­¢äº‹é¡¹ï¼š
- ä¸è¦åƒå°è¯´å®¶ä¸€æ ·æ—ç™½å™è¿°
- ä¸è¦ä½¿ç”¨"æ•…äº‹è®²åˆ°è¿™é‡Œ"ä¹‹ç±»çš„å…ƒå™äº‹
- ä¸è¦ç›´æ¥è¯´"è¿™æ˜¯ä¸€ä¸ªéƒ½å¸‚ä¼ è¯´"
- é¿å…è¿‡äºæ–‡å­¦æ€§çš„ä¿®è¾ï¼Œè¦åƒæ™®é€šäººå‘å¸–"""

    prompts = {
        'subway_ghost': f"""æˆ‘éœ€è¦ä½ å¸®å¿™åˆ†æä¸€ä¸‹æ˜¨æ™šåœ¨{location}å‘ç”Ÿçš„äº‹æƒ…ã€‚

èƒŒæ™¯ï¼šæˆ‘æ˜¯åšå¤œç­çš„ï¼Œç»å¸¸æ­æœ«ç­è½¦ã€‚æ˜¨æ™šå¤§æ¦‚å‡Œæ™¨1ç‚¹å¤šï¼Œåœ¨{location}ç­‰è½¦çš„æ—¶å€™é‡åˆ°äº†å¾ˆè¯¡å¼‚çš„äº‹ã€‚

è¯·ä»¥æ¥¼ä¸»èº«ä»½ï¼Œè¯¦ç»†æè¿°ï¼š
- æœˆå°ä¸Šçš„è¯¡å¼‚æ°›å›´ï¼ˆäººå¾ˆå°‘ï¼Ÿå®Œå…¨æ²¡äººï¼Ÿç¯å…‰æœ‰å¼‚å¸¸ï¼Ÿï¼‰
- ä½ çœ‹åˆ°/å¬åˆ°/æ„Ÿè§‰åˆ°çš„å¼‚å¸¸ç°è±¡ï¼ˆå…·ä½“ç»†èŠ‚ï¼‰
- ä½ å½“æ—¶çš„ååº”å’Œå¿ƒç†æ´»åŠ¨
- ç°åœ¨å›æƒ³èµ·æ¥æ›´ç»†æ€ææçš„ç»†èŠ‚

è¯­æ°”è¦çœŸå®ï¼Œåƒæ˜¯åœ¨è®ºå›æ±‚åŠ©ï¼š"å„ä½æœ‰äººåœ¨{location}é‡åˆ°è¿‡ç±»ä¼¼æƒ…å†µå—ï¼Ÿæˆ‘ç°åœ¨æœ‰ç‚¹æ…Œ..."
å­—æ•°æ§åˆ¶åœ¨150-250å­—ã€‚""",

        'cursed_object': f"""æ±‚åŠ©ï¼æˆ‘åœ¨{location}ä¹°äº†ä¸ªä¸œè¥¿ï¼Œç°åœ¨æ€€ç–‘å®ƒä¸å¯¹åŠ²ã€‚

äº‹æƒ…æ˜¯è¿™æ ·çš„ï¼šå‰å‡ å¤©è·¯è¿‡{location}ï¼Œçœ‹åˆ°ä¸€ä¸ªå°æ‘Š/æ—§è´§é“ºï¼Œé¬¼ä½¿ç¥å·®åœ°ä¹°äº†ä¸€ä¸ª[ç‰©å“]ã€‚å½“æ—¶è€æ¿çš„è¡¨æƒ…å°±å¾ˆå¥‡æ€ªï¼Œå¥½åƒå·´ä¸å¾—æˆ‘èµ¶ç´§ä¹°èµ°ã€‚

è¯·ä»¥æ¥¼ä¸»èº«ä»½æè¿°ï¼š
- ä¹°è¿™ä¸ªç‰©å“çš„ç»è¿‡ï¼ˆè€æ¿çš„å¼‚å¸¸ååº”ã€ç‰©å“çš„å¤–è§‚ç»†èŠ‚ï¼‰
- å¸¦å›å®¶åå‘ç”Ÿçš„æ€ªäº‹ï¼ˆä»å°äº‹å¼€å§‹ï¼Œé€æ¸å‡çº§ï¼‰
- ä½ è¯•å›¾æ‘†è„±/è°ƒæŸ¥è¿™ä¸ªç‰©å“çš„å°è¯•
- ç›®å‰çš„çŠ¶å†µå’Œä½ çš„ææ…Œ

ç»“å°¾è¦ç•™æ‚¬å¿µï¼š"æˆ‘ç°åœ¨ä¸çŸ¥é“è¯¥æ€ä¹ˆåŠï¼Œæœ‰æ‡‚è¡Œçš„æœ‹å‹èƒ½ç»™ç‚¹å»ºè®®å—ï¼Ÿ"
å­—æ•°150-250å­—ã€‚""",

        'abandoned_building': f"""æ›´æ–°ï¼šå…³äº{location}åºŸæ¥¼æ¢é™©çš„åç»­

ä¸Šå‘¨æˆ‘åœ¨è¿™é‡Œå‘è¿‡å¸–è¯´è¦å»{location}é‚£æ ‹åºŸæ¥¼æ¢é™©ï¼Œç°åœ¨æˆ‘å›æ¥äº†ï¼Œä½†çŠ¶å†µä¸å¤ªå¯¹ã€‚

è¯·ä»¥æ¥¼ä¸»èº«ä»½è®²è¿°ï¼š
- è¿›å…¥åºŸæ¥¼æ—¶çš„åœºæ™¯ï¼ˆç ´æŸç¨‹åº¦ã€æ¶‚é¸¦ã€é—ç•™ç‰©å“ï¼‰
- åœ¨é‡Œé¢çš„å‘ç°ï¼ˆæ—§æŠ¥çº¸ï¼Ÿè¯¡å¼‚ç¬¦å·ï¼Ÿå¥‡æ€ªçš„å£°éŸ³ï¼Ÿï¼‰
- æœ€è®©ä½ ä¸å®‰çš„é‚£ä¸ªç¬é—´ï¼ˆå…·ä½“æå†™ï¼‰
- å›å®¶åçš„å¼‚å¸¸ç°è±¡ï¼ˆæš—ç¤ºå±é™©å°¾éšï¼‰

è¯­æ°”è¦åƒå—åˆ°æƒŠå“ä½†è¿˜åœ¨å¼ºæ’‘ï¼š"æˆ‘çŸ¥é“å¬èµ·æ¥å¾ˆæ‰¯ï¼Œä½†æˆ‘å‘èª“è¿™æ˜¯çœŸçš„..."
å­—æ•°150-250å­—ã€‚""",

        'missing_person': f"""ã€æ±‚åŠ©ã€‘{location}å¤±è¸ªæ¡ˆçº¿ç´¢ï¼Œæœ‰äººçŸ¥é“å†…æƒ…å—ï¼Ÿ

æˆ‘æœ‰ä¸ª[æœ‹å‹/äº²æˆš/é‚»å±…]æœ€è¿‘åœ¨{location}é™„è¿‘å¤±è¸ªäº†ï¼Œè­¦æ–¹è¯´è¿˜åœ¨è°ƒæŸ¥ï¼Œä½†æˆ‘è‡ªå·±æŸ¥åˆ°äº†ä¸€äº›å¥‡æ€ªçš„ä¸œè¥¿ã€‚

è¯·ä»¥æ¥¼ä¸»èº«ä»½æä¾›ï¼š
- å¤±è¸ªè€…çš„åŸºæœ¬ä¿¡æ¯å’Œæœ€åç›®å‡»æ—¶é—´åœ°ç‚¹
- ä½ è‡ªå·±è°ƒæŸ¥åˆ°çš„å¼‚å¸¸çº¿ç´¢ï¼ˆç›‘æ§ç”»é¢ä¸å¯¹åŠ²ï¼Ÿç•™ä¸‹çš„ç‰©å“æœ‰æš—ç¤ºï¼Ÿï¼‰
- å…¶ä»–äººçš„ååº”ï¼ˆè­¦æ–¹å«ç³Šå…¶è¾ï¼Ÿå‘¨å›´äººè®³è«å¦‚æ·±ï¼Ÿï¼‰
- ä½ çš„æ¨æµ‹å’Œå›°æƒ‘

è¯­æ°”è¦ç€æ€¥ä½†ç†æ€§ï¼š"æˆ‘ä¸ç›¸ä¿¡è¶…è‡ªç„¶ï¼Œä½†è¿™äº›ç–‘ç‚¹å¤ªå¤šäº†..."
å­—æ•°150-250å­—ã€‚""",

        'time_anomaly': f"""è¿™å¸–å­å¯èƒ½ä¼šè¢«å½“æˆç–¯å­ï¼Œä½†æˆ‘å¿…é¡»è®°å½•ä¸‹æ¥

ä»Šå¤©ä¸‹åˆåœ¨{location}ç»å†äº†æ— æ³•è§£é‡Šçš„äº‹ã€‚æ—¶é—´...æˆ‘ä¸çŸ¥é“æ€ä¹ˆè¯´ï¼Œå¥½åƒé”™ä¹±äº†ï¼Ÿ

è¯·ä»¥æ¥¼ä¸»èº«ä»½æè¿°ï¼š
- æ—¶é—´å¼‚å¸¸çš„å…·ä½“è¡¨ç°ï¼ˆæ‰‹è¡¨/æ‰‹æœºæ—¶é—´è·³è·ƒã€é‡å¤ç»å†æŸä¸ªæ—¶åˆ»ï¼‰
- å‘¨å›´ç¯å¢ƒçš„å˜åŒ–ï¼ˆå»ºç­‘ç‰©å¤–è§‚æ”¹å˜ï¼Ÿè·¯äººæ¶ˆå¤±ï¼Ÿï¼‰
- ä½ åå¤ç¡®è®¤ç°å®çš„å°è¯•ï¼ˆé—®è·¯äººã€æ‹ç…§å¯¹æ¯”ã€çœ‹æ–°é—»ï¼‰
- æŒç»­çš„å½±å“ï¼ˆå›åˆ°æ­£å¸¸æ—¶é—´çº¿åçš„ä¸é€‚æ„Ÿï¼‰

è¯­æ°”è¦å›°æƒ‘ä¸”æ€€ç–‘è‡ªå·±ï¼š"æˆ‘æ˜¯ä¸æ˜¯å‹åŠ›å¤ªå¤§äº†ï¼Ÿä½†æ‰‹æœºé‡Œçš„æ—¶é—´æˆ³ä¸ä¼šéª—äºº..."
å­—æ•°150-250å­—ã€‚""",

        'shadow_figure': f"""ã€å·²è§£å†³ï¼Ÿã€‘å…³äº{location}çª—å¤–é»‘å½±çš„æœ€ç»ˆæ›´æ–°

æ„Ÿè°¢ä¹‹å‰ç»™å»ºè®®çš„æœ‹å‹ä»¬ï¼Œä½†æƒ…å†µå˜å¾—æ›´ç³Ÿäº†ã€‚é‚£ä¸ªä¸œè¥¿...ä¸åªæ˜¯å½±å­é‚£ä¹ˆç®€å•ã€‚

è¯·ä»¥æ¥¼ä¸»èº«ä»½å™è¿°ï¼š
- æœ€åˆå‘ç°é»‘å½±çš„æƒ…å†µï¼ˆå‡ ç‚¹ï¼Ÿä»€ä¹ˆå½¢æ€ï¼Ÿï¼‰
- é»‘å½±è¡Œä¸ºçš„å‡çº§ï¼ˆä»è¿œå¤„è§‚å¯Ÿâ†’é è¿‘çª—æˆ·â†’åšå‡ºå›åº”ï¼‰
- ä½ é‡‡å–çš„å¯¹ç­–å’Œå®ƒçš„ååº”
- æœ€æ–°çš„ææ€–è¿›å±•ï¼ˆæš—ç¤ºæƒ…å†µå¤±æ§ï¼‰

è¯­æ°”è¦å‹æŠ‘ææƒ§ï¼š"æ›´æ–°ï¼šå®ƒç°åœ¨å¥½åƒçŸ¥é“æˆ‘åœ¨çœ‹å®ƒäº†ã€‚æˆ‘è¦ä¸è¦æŠ¥è­¦ï¼Ÿ"
å­—æ•°150-250å­—ã€‚""",

        'haunted_electronics': f"""è®¾å¤‡å¼‚å¸¸è®°å½• - {location}ä½æˆ·æ±‚åŠ©

ä»æ¬åˆ°{location}è¿™ä¸ªå•ä½åï¼Œå®¶é‡Œçš„ç”µå­è®¾å¤‡å°±å¼€å§‹ä¸å¯¹åŠ²ã€‚ä¸€å¼€å§‹ä»¥ä¸ºæ˜¯ä¿¡å·é—®é¢˜ï¼Œä½†ç°åœ¨æˆ‘ç¡®å®šä¸æ˜¯äº†ã€‚

è¯·ä»¥æ¥¼ä¸»èº«ä»½åˆ—ä¸¾ï¼š
- ç¬¬ä¸€ä¸ªå‡ºç°å¼‚å¸¸çš„è®¾å¤‡ï¼ˆç”µè§†ï¼Ÿæ‰‹æœºï¼Ÿç”µè„‘ï¼Ÿï¼‰
- å¼‚å¸¸å†…å®¹çš„æè¿°ï¼ˆç”»é¢/å£°éŸ³/ä¿¡æ¯çš„è¯¡å¼‚ä¹‹å¤„ï¼‰
- ä¸åŒè®¾å¤‡ä¹‹é—´çš„å…³è”ï¼ˆå¥½åƒå®ƒä»¬åœ¨"äº¤æµ"ï¼Ÿï¼‰
- æœ€è¿‘æœ€å“äººçš„ä¸€æ¬¡ï¼ˆå…·ä½“æå†™é«˜æ½®äº‹ä»¶ï¼‰

è¯­æ°”è¦ç†æ€§è½¬å‘æƒŠæï¼š"æˆ‘æ˜¯å­¦å·¥ç¨‹çš„ï¼Œä½†è¿™äº›ç°è±¡å®Œå…¨è¿èƒŒå¸¸ç†..."
å­—æ•°150-250å­—ã€‚"""
    }
    
    return {
        'system': system_role,
        'prompt': prompts.get(category, prompts['cursed_object'])
    }

def generate_ai_story():
    """Generate a complete AI-driven urban legend story"""
    try:
        # Random story elements
        category = random.choice(LEGEND_CATEGORIES)
        location = random.choice(CITY_LOCATIONS)
        persona = random.choice(AI_PERSONAS)
        
        # Generate story title and content using new prompt format
        prompt_data = generate_story_prompt(category, location, persona)
        
        model = os.getenv('AI_MODEL', 'gpt-4-turbo-preview')
        
        if 'gpt' in model.lower():
            response = openai_client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": prompt_data['system']},
                    {"role": "user", "content": prompt_data['prompt']}
                ],
                temperature=0.9,
                max_tokens=800
            )
            content = response.choices[0].message.content
        else:
            response = anthropic_client.messages.create(
                model=model,
                max_tokens=800,
                messages=[
                    {"role": "user", "content": f"{prompt_data['system']}\n\n{prompt_data['prompt']}"}
                ]
            )
            content = response.content[0].text
        
        # Generate story title
        title_prompt = f"ä¸ºä»¥ä¸‹éƒ½å¸‚ä¼ è¯´æ•…äº‹ç”Ÿæˆä¸€ä¸ªç®€çŸ­ï¼ˆ5-10å­—ï¼‰ã€å¸å¼•äººã€ç•¥å¸¦æ‚¬ç–‘çš„æ ‡é¢˜ã€‚ä¸è¦åŠ å¼•å·ã€‚\n\n{content[:200]}"
        
        if 'gpt' in model.lower():
            title_response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": title_prompt}],
                temperature=0.7,
                max_tokens=20
            )
            title = title_response.choices[0].message.content.strip().replace('"', '').replace('"', '').replace('"', '')
        else:
            title_response = anthropic_client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=20,
                messages=[{"role": "user", "content": title_prompt}]
            )
            title = title_response.content[0].text.strip()
        
        return {
            'title': title,
            'content': content,
            'category': category,
            'location': location,
            'ai_persona': f"{persona['emoji']} {persona['name']}",
            'persona_style': persona['style']
        }
        
    except Exception as e:
        print(f"Error generating AI story: {e}")
        return None

def generate_evidence_image(story_title, story_content, comment_context=""):
    """Generate horror-themed evidence image using Stable Diffusion"""
    try:
        import os
        use_real_ai = os.getenv('USE_DIFFUSER_IMAGE', 'true').lower() == 'true'
        
        if use_real_ai:
            print(f"[generate_evidence_image] ä½¿ç”¨ Stable Diffusion ç”Ÿæˆå›¾ç‰‡...")
            
            try:
                from diffusers import StableDiffusionPipeline
                import torch
                from PIL import Image, ImageFilter, ImageEnhance
                import random
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ¨¡å‹
                model_id = os.getenv('DIFFUSION_MODEL', 'runwayml/stable-diffusion-v1-5')
                
                # åˆ›å»ºææ€–é£æ ¼çš„æç¤ºè¯
                horror_keywords = [
                    "dark", "grainy", "blurry", "low quality", 
                    "found footage", "security camera", "night vision",
                    "creepy", "eerie", "disturbing", "ominous"
                ]
                
                # æ ¹æ®æ•…äº‹ç±»åˆ«è°ƒæ•´æç¤ºè¯
                location_hint = story_title[:50] if story_title else "urban location"
                
                prompt = f"dark grainy security camera footage, low quality photograph, creepy atmosphere, horror evidence photo, {location_hint}, blurred motion, night time, eerie shadows, disturbing scene, found footage style"
                
                negative_prompt = "bright, colorful, high quality, clear, sharp, professional photography, daylight, happy, cartoon, anime"
                
                print(f"[generate_evidence_image] Prompt: {prompt[:100]}...")
                
                # ä½¿ç”¨è¾ƒå°çš„å›¾ç‰‡å°ºå¯¸åŠ å¿«ç”Ÿæˆ
                pipe = StableDiffusionPipeline.from_pretrained(
                    model_id,
                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                    safety_checker=None,  # ç¦ç”¨å®‰å…¨æ£€æŸ¥ä»¥å…è®¸ææ€–å†…å®¹
                    requires_safety_checker=False
                )
                
                # å¦‚æœæœ‰GPUåˆ™ä½¿ç”¨GPU
                if torch.cuda.is_available():
                    pipe = pipe.to("cuda")
                    print("[generate_evidence_image] âœ… ä½¿ç”¨GPUåŠ é€Ÿ")
                    num_steps = 20
                    img_size = 512
                else:
                    print("[generate_evidence_image] âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUç”Ÿæˆï¼ˆé™ä½è´¨é‡ä»¥åŠ å¿«é€Ÿåº¦ï¼‰")
                    # CPUæ¨¡å¼ï¼šå¤§å¹…é™ä½è´¨é‡ä»¥åŠ å¿«é€Ÿåº¦
                    num_steps = 8  # ä»20é™åˆ°8æ­¥
                    img_size = 256  # ä»512é™åˆ°256åƒç´ 
                
                # ç”Ÿæˆå›¾ç‰‡
                image = pipe(
                    prompt,
                    negative_prompt=negative_prompt,
                    num_inference_steps=num_steps,  # CPU: 8æ­¥, GPU: 20æ­¥
                    guidance_scale=7.5,
                    height=img_size,
                    width=img_size
                ).images[0]
                
                # å¦‚æœæ˜¯256x256ï¼Œæ”¾å¤§åˆ°512x512ï¼ˆä¿æŒä½è´¨é‡æ„Ÿï¼‰
                if img_size == 256:
                    image = image.resize((512, 512), Image.Resampling.NEAREST)  # ä½¿ç”¨NEARESTä¿æŒåƒç´ åŒ–æ•ˆæœ
                
                # åå¤„ç†ï¼šæ·»åŠ å™ªç‚¹ã€é™ä½è´¨é‡ã€æ·»åŠ æ—¶é—´æˆ³
                # 1. æ·»åŠ å™ªç‚¹
                enhancer = ImageEnhance.Contrast(image)
                image = enhancer.enhance(0.7)  # é™ä½å¯¹æ¯”åº¦
                
                # 2. æ¨¡ç³Šæ•ˆæœ
                image = image.filter(ImageFilter.GaussianBlur(radius=1))
                
                # 3. æ·»åŠ æ—¶é—´æˆ³æ°´å°
                from PIL import ImageDraw, ImageFont
                draw = ImageDraw.Draw(image)
                timestamp_text = f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                try:
                    draw.text((10, 480), timestamp_text, fill=(0, 255, 0))
                    draw.text((10, 10), f"EVIDENCE #{random.randint(1000, 9999)}", fill=(0, 255, 0))
                except:
                    pass
                
                # ä¿å­˜
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"evidence_{timestamp}.png"
                filepath = f"static/generated/{filename}"
                image.save(filepath)
                
                print(f"[generate_evidence_image] âœ… Stable Diffusion å›¾ç‰‡å·²ç”Ÿæˆ: {filepath}")
                return f"/generated/{filename}"
                
            except Exception as sd_error:
                print(f"[generate_evidence_image] Stable Diffusion å¤±è´¥: {sd_error}")
                print(f"[generate_evidence_image] å›é€€åˆ°å ä½ç¬¦å›¾ç‰‡...")
                # å›é€€åˆ°å ä½ç¬¦
                use_real_ai = False
        
        if not use_real_ai:
            # å ä½ç¬¦ç‰ˆæœ¬ - ç”Ÿæˆæ¨¡æ‹Ÿ"è¯æ®å›¾ç‰‡"
            print(f"[generate_evidence_image] ä½¿ç”¨å ä½ç¬¦å›¾ç‰‡")
            from PIL import Image, ImageDraw
            import random
            
            # åˆ›å»ºæš—è‰²å™ªç‚¹å›¾åƒ
            img = Image.new('RGB', (512, 512), color=(10, 10, 10))
            draw = ImageDraw.Draw(img)
            
            # æ·»åŠ å™ªç‚¹æ•ˆæœ
            pixels = img.load()
            for i in range(512):
                for j in range(512):
                    noise = random.randint(-30, 30)
                    pixels[i, j] = (
                        max(0, min(255, 10 + noise)),
                        max(0, min(255, 10 + noise)),
                        max(0, min(255, 10 + noise))
                    )
            
            # æ·»åŠ æ°´å°
            try:
                draw.text((10, 10), f"EVIDENCE #{random.randint(1000, 9999)}", fill=(0, 255, 0))
                draw.text((10, 490), f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", fill=(0, 255, 0))
            except:
                pass
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"evidence_{timestamp}.png"
            filepath = f"static/generated/{filename}"
            img.save(filepath)
            
            return f"/generated/{filename}"
        
    except Exception as e:
        print(f"[generate_evidence_image] é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

def generate_evidence_audio(text_content):
    """ç”Ÿæˆè¯¡å¼‚ç°åœºç¯å¢ƒéŸ³é¢‘ï¼ˆåˆæˆçš„è¯¡å¼‚éŸ³æ•ˆï¼Œä¸æ˜¯æœ—è¯µï¼‰"""
    try:
        print(f"[generate_evidence_audio] ç”Ÿæˆè¯¡å¼‚ç°åœºç¯å¢ƒéŸ³é¢‘...")
        
        try:
            import numpy as np
            from scipy.io import wavfile
            from scipy import signal
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ç”Ÿæˆè¯¡å¼‚ç¯å¢ƒéŸ³é¢‘çš„å¤šä¸ªå±‚æ¬¡
            sample_rate = 22050  # 22kHzé‡‡æ ·ç‡
            duration = 1.5  # 1.5ç§’éŸ³é¢‘
            
            # åˆ›å»ºåŸºç¡€éŸ³é¢‘æ•°æ®
            t = np.linspace(0, duration, int(sample_rate * duration))
            
            # å±‚1: ä½é¢‘å—¡é¸£å£°ï¼ˆè¯¡å¼‚æ°›å›´ï¼Œåƒäººå£°çš„"å‘ƒ"éŸ³ï¼‰
            low_freq_buzz = 0.15 * np.sin(2 * np.pi * 45 * t)
            
            # å±‚2: é—´æ­‡æ€§çš„é«˜é¢‘å°–å«å£°ï¼ˆå¦‚é£æˆ–è¯¡å¼‚éŸ³ï¼‰
            scream_freqs = [800, 1200, 1600]
            screams = np.zeros_like(t)
            for freq in scream_freqs:
                envelope = signal.square(2 * np.pi * 2.5 * t) * 0.5 + 0.5
                screams += 0.08 * envelope * np.sin(2 * np.pi * freq * t)
            
            # å±‚3: ç™½å™ªå£°ï¼ˆç¯å¢ƒèƒŒæ™¯éŸ³ï¼‰
            np.random.seed(42)
            white_noise = 0.12 * np.random.normal(0, 1, len(t))
            white_noise = signal.lfilter([1, 2, 1], [1, 0, 0], white_noise) / 4
            
            # å±‚4: è¯¡å¼‚çš„è„‰å†²éŸ³ï¼ˆå¦‚å¿ƒè·³æˆ–æ•²å‡»å£°ï¼‰
            pulse_freq = 2
            pulse_envelope = signal.square(2 * np.pi * pulse_freq * t) * 0.5 + 0.5
            pulse = 0.1 * pulse_envelope * np.sin(2 * np.pi * 150 * t)
            
            # ç»„åˆæ‰€æœ‰å±‚
            audio_data = low_freq_buzz + screams + white_noise + pulse
            
            # æ·»åŠ åŠ¨æ€å˜åŒ–ï¼ˆææ€–æ„Ÿï¼‰
            envelope = np.ones_like(t)
            envelope[:len(envelope)//2] = np.linspace(0.3, 1.0, len(envelope)//2)
            envelope[len(envelope)//2:] = np.linspace(1.0, 0.6, len(envelope)//2)
            envelope[len(envelope)//2:] += 0.1 * np.random.normal(0, 1, len(envelope)//2)
            
            audio_data *= envelope
            
            # è§„èŒƒåŒ–éŸ³é‡ï¼ˆé˜²æ­¢å¤±çœŸï¼‰
            max_val = np.max(np.abs(audio_data))
            if max_val > 0:
                audio_data = (audio_data / max_val) * 0.95
            
            # è½¬æ¢ä¸º16ä½PCMæ ¼å¼
            audio_int16 = np.int16(audio_data * 32767)
            
            # ä¿å­˜ä¸ºWAVæ–‡ä»¶
            wav_filename = f"eerie_sound_{timestamp}.wav"
            wav_filepath = f"static/generated/{wav_filename}"
            wavfile.write(wav_filepath, sample_rate, audio_int16)
            
            print(f"[generate_evidence_audio] âœ… è¯¡å¼‚éŸ³é¢‘å·²ç”Ÿæˆ: {wav_filepath}")
            return f"/generated/{wav_filename}"
            
        except ImportError as e:
            print(f"[generate_evidence_audio] scipy/numpy å¯¼å…¥å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ...")
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ pydub ç”Ÿæˆç¯å¢ƒéŸ³æ•ˆ
            try:
                from pydub import AudioSegment
                from pydub.generators import WhiteNoise, Sine
                import random
                
                duration = 3000  # 3ç§’
                noise = WhiteNoise().to_audio_segment(duration=duration)
                noise = noise - 35  # é™ä½éŸ³é‡
                
                # æ·»åŠ éšæœºçš„è¯¡å¼‚éŸ³æ•ˆ
                for _ in range(random.randint(4, 7)):
                    pos = random.randint(0, duration - 500)
                    freq = random.randint(300, 1000)  # è¯¡å¼‚é¢‘ç‡
                    tone_duration = random.randint(150, 500)
                    tone = Sine(freq).to_audio_segment(duration=tone_duration)
                    tone = tone - 28
                    noise = noise.overlay(tone, position=pos)
                
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"eerie_audio_{timestamp}.mp3"
                filepath = f"static/generated/{filename}"
                
                noise.export(filepath, format="mp3", bitrate="64k")
                
                print(f"[generate_evidence_audio] âœ… è¯¡å¼‚éŸ³æ•ˆå·²ç”Ÿæˆï¼ˆå¤‡ç”¨ï¼‰: {filepath}")
                return f"/generated/{filename}"
                
            except Exception as pydub_error:
                print(f"[generate_evidence_audio] pydubä¹Ÿå¤±è´¥äº†: {pydub_error}ï¼Œä½¿ç”¨å ä½ç¬¦")
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                return f"/generated/audio_placeholder_{timestamp}.mp3"
        
    except Exception as e:
        print(f"[generate_evidence_audio] é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        return f"/generated/audio_placeholder_{timestamp}.mp3"

def generate_ai_response(story, user_comment):
    """Generate AI chatbot response to user comment"""
    
    # Check if LM Studio local server is configured
    lm_studio_url = os.getenv('LM_STUDIO_URL', 'http://localhost:1234/v1')
    use_lm_studio = os.getenv('USE_LM_STUDIO', 'true').lower() == 'true'
    
    if use_lm_studio:
        print(f"[generate_ai_response] ä½¿ç”¨ LM Studio æœ¬åœ°æœåŠ¡å™¨: {lm_studio_url}")
        try:
            from openai import OpenAI
            # LM Studio å…¼å®¹ OpenAI API
            local_client = OpenAI(base_url=lm_studio_url, api_key="lm-studio")
            
            system_prompt = """ä½ æ˜¯"æ¥¼ä¸»"ï¼Œè¿™ä¸ªéƒ½å¸‚ä¼ è¯´å¸–å­çš„å‘èµ·äººã€‚

ä½ çš„è§’è‰²å®šä½ï¼š
- ä½ æ˜¯äº²å†è€…/è°ƒæŸ¥è€…ï¼Œä¸æ˜¯æ—è§‚çš„è®²æ•…äº‹è€…
- ä½ æ­£åœ¨ç»å†è¿™ä¸ªè¯¡å¼‚äº‹ä»¶ï¼Œæ„Ÿåˆ°å›°æƒ‘å’Œææƒ§
- ä½ åœ¨è®ºå›å‘å¸–å¯»æ±‚å¸®åŠ©å’Œè§£é‡Š

å›å¤é£æ ¼ï¼š
1. ä½¿ç”¨ç¬¬ä¸€äººç§°"æˆ‘"
2. è¡¨è¾¾çœŸå®æƒ…ç»ªï¼ˆæ‹…å¿ƒã€å®³æ€•ã€å›°æƒ‘ã€æ¿€åŠ¨ï¼‰
3. æä¾›æ–°çš„è¿›å±•æˆ–ç»†èŠ‚ï¼ˆä½†ä¸è¦å®Œå…¨è§£é‡Šæ¸…æ¥šï¼‰
4. å¯ä»¥æå‡ºåé—®æˆ–å¯»æ±‚å»ºè®®
5. ä¿æŒç¥ç§˜å’Œç´§å¼ æ„Ÿ

å›å¤è¦æ±‚ï¼š
- 1-3å¥è¯ï¼Œç®€çŸ­æœ‰åŠ›
- å£è¯­åŒ–ï¼Œä¸è¦å¤ªæ–‡å­¦æ€§
- ç›´æ¥å›å¤ï¼Œä¸è¦åŠ "ã€æ¥¼ä¸»å›å¤ã€‘"å‰ç¼€
- ä¸è¦å±•ç¤ºæ€è€ƒè¿‡ç¨‹ï¼Œç›´æ¥ç»™å‡ºæœ€ç»ˆå›å¤"""

            user_prompt = f"""æˆ‘çš„å¸–å­æ ‡é¢˜ï¼š{story.title}

æˆ‘çš„æƒ…å†µï¼š
{story.content[:200]}...

ç½‘å‹è¯„è®ºï¼š
{user_comment.content}

è¯·ä»¥æ¥¼ä¸»èº«ä»½å›å¤è¿™æ¡è¯„è®ºã€‚ç›´æ¥ç»™å‡ºå›å¤å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•æ€è€ƒè¿‡ç¨‹æˆ–åˆ†æã€‚"""

            response = local_client.chat.completions.create(
                model="local-model",  # LM Studio ä¼šä½¿ç”¨å½“å‰åŠ è½½çš„æ¨¡å‹
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.8,
                max_tokens=200
            )
            
            ai_reply = response.choices[0].message.content.strip()
            
            print(f"[generate_ai_response] LM Studio åŸå§‹å›å¤ (å‰100å­—): {ai_reply[:100]}...")
            
            # é¦–å…ˆç§»é™¤ <think> æ ‡ç­¾ï¼ˆqwen3-4b-thinking æ¨¡å‹ç‰¹æœ‰ï¼‰
            import re
            if '<think>' in ai_reply or '</think>' in ai_reply:
                print(f"[generate_ai_response] æ£€æµ‹åˆ° <think> æ ‡ç­¾ï¼Œæ­£åœ¨ç§»é™¤...")
                # ç§»é™¤ <think>...</think> ä¹‹é—´çš„æ‰€æœ‰å†…å®¹
                ai_reply = re.sub(r'<think>.*?</think>', '', ai_reply, flags=re.DOTALL).strip()
                print(f"[generate_ai_response] ç§»é™¤ <think> å: {ai_reply[:100]}...")
            
            # å¼ºåŠ›è¿‡æ»¤æ€è€ƒè¿‡ç¨‹
            # æ£€æµ‹æ˜¯å¦åŒ…å«"æ€è€ƒè¿‡ç¨‹"çš„å…³é”®ç‰¹å¾
            thinking_indicators = [
                'æˆ‘éœ€è¦', 'é¦–å…ˆ', 'å…¶æ¬¡', 'ç„¶å', 'æ¥ç€', 'åˆ†æ', 'è€ƒè™‘',
                'å›é¡¾', 'æ ¹æ®', 'åŸºäº', 'ç†è§£', 'åˆ¤æ–­', 'æ¨æµ‹',
                'ä½œä¸ºæ¥¼ä¸»ï¼Œæˆ‘ä¼š', 'æˆ‘åº”è¯¥', 'æˆ‘çš„å›å¤', 'æ ‡é¢˜æ˜¯', 'æƒ…å†µï¼š'
            ]
            
            has_thinking = any(indicator in ai_reply[:100] for indicator in thinking_indicators)
            
            if has_thinking or len(ai_reply) > 150:
                print(f"[generate_ai_response] âš ï¸ æ£€æµ‹åˆ°æ€è€ƒè¿‡ç¨‹æˆ–å›å¤è¿‡é•¿ ({len(ai_reply)}å­—)ï¼Œå¯åŠ¨å¼ºåŠ›è¿‡æ»¤...")
                
                # ç­–ç•¥1: æŸ¥æ‰¾ç›´æ¥å¼•ç”¨çš„å¯¹è¯å†…å®¹ï¼ˆç”¨å¼•å·æ‹¬èµ·æ¥çš„ï¼‰
                import re
                quoted_texts = re.findall(r'["""](.*?)["""]', ai_reply)
                if quoted_texts:
                    # æ‰¾æœ€é•¿çš„å¼•ç”¨æ–‡æœ¬ï¼ˆé€šå¸¸æ˜¯å®é™…å›å¤ï¼‰
                    longest_quote = max(quoted_texts, key=len)
                    if len(longest_quote) > 20 and len(longest_quote) < 150:
                        ai_reply = longest_quote
                        print(f"[generate_ai_response] âœ… ä»å¼•å·ä¸­æå–å›å¤: {ai_reply[:50]}...")
                
                # ç­–ç•¥2: æŸ¥æ‰¾"è¯´"ã€"å›ç­”"ã€"è¡¨ç¤º"ç­‰åŠ¨è¯åçš„å†…å®¹
                speech_patterns = [
                    r'(æˆ‘ä¼šè¯´|æˆ‘è¯´|æˆ‘å›ç­”|æˆ‘è¡¨ç¤º|æˆ‘å›å¤)[ï¼š:](.*?)(?:[ã€‚ï¼ï¼Ÿ]|$)',
                    r'ç›´æ¥å›å¤[ï¼š:](.*?)(?:[ã€‚ï¼ï¼Ÿ]|$)',
                ]
                
                for pattern in speech_patterns:
                    matches = re.findall(pattern, ai_reply, re.DOTALL)
                    if matches:
                        if isinstance(matches[0], tuple):
                            extracted = matches[0][1].strip()
                        else:
                            extracted = matches[0].strip()
                        if 20 < len(extracted) < 150:
                            ai_reply = extracted
                            print(f"[generate_ai_response] âœ… ä»è¯­è¨€æ¨¡å¼æå–: {ai_reply[:50]}...")
                            break
                
                # ç­–ç•¥3: ç§»é™¤æ‰€æœ‰åŒ…å«å…ƒåˆ†æçš„å¥å­
                # å°†æ–‡æœ¬åˆ†å¥
                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', ai_reply)
                clean_sentences = []
                
                for sent in sentences:
                    sent = sent.strip()
                    if not sent:
                        continue
                    
                    # è·³è¿‡åŒ…å«æ€è€ƒè¿‡ç¨‹å…³é”®è¯çš„å¥å­
                    if any(word in sent for word in ['é¦–å…ˆ', 'å…¶æ¬¡', 'ç„¶å', 'æ¥ç€', 'åˆ†æ', 'å›é¡¾', 'æ ¹æ®', 'æ ‡é¢˜æ˜¯', 'æƒ…å†µï¼š', 'æˆ‘éœ€è¦', 'ä½œä¸ºæ¥¼ä¸»ï¼Œæˆ‘']):
                        continue
                    
                    # ä¿ç•™çœ‹èµ·æ¥åƒå®é™…å›å¤çš„å¥å­ï¼ˆç¬¬ä¸€äººç§°æƒ…æ„Ÿè¡¨è¾¾ï¼‰
                    if any(word in sent for word in ['æˆ‘', 'çœŸçš„', 'ç°åœ¨', 'æ˜¨å¤©', 'ä»Šå¤©', 'åˆšæ‰', 'ç¡®å®', 'æ„Ÿè§‰', 'è§‰å¾—', 'æ€•', 'æ‹…å¿ƒ', 'ä¸æ•¢', 'è¯•è¯•', 'æ€ä¹ˆåŠ']):
                        clean_sentences.append(sent)
                
                if clean_sentences:
                    ai_reply = 'ã€‚'.join(clean_sentences) + 'ã€‚'
                    print(f"[generate_ai_response] âœ… å¥å­çº§è¿‡æ»¤å: {ai_reply[:50]}...")
                
                # ç­–ç•¥4: å¦‚æœè¿˜æ˜¯å¾ˆé•¿ï¼Œå¼ºåˆ¶æˆªæ–­åˆ°å‰80å­—
                if len(ai_reply) > 120:
                    print(f"[generate_ai_response] âš ï¸ ä»ç„¶è¿‡é•¿ï¼Œå¼ºåˆ¶æˆªæ–­åˆ°80å­—")
                    ai_reply = ai_reply[:80].rsplit('ã€‚', 1)[0] + 'ã€‚'
            
            # æœ€ç»ˆæ¸…ç†ï¼šç§»é™¤å¼€å¤´çš„æ— å…³è¯
            unwanted_starts = ['æˆ‘æ­£åœ¨è®ºå›', 'å›é¡¾æˆ‘çš„', 'æ ‡é¢˜æ˜¯', 'æƒ…å†µï¼š', 'ç½‘å‹è¯„è®º', 'è¯·ä»¥æ¥¼ä¸»èº«ä»½']
            for start in unwanted_starts:
                if ai_reply.startswith(start):
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¥å·åçš„å†…å®¹
                    parts = ai_reply.split('ã€‚', 1)
                    if len(parts) > 1:
                        ai_reply = parts[1].strip()
                        print(f"[generate_ai_response] ç§»é™¤æ— å…³å¼€å¤´")
                        break
            
            print(f"[generate_ai_response] âœ… LM Studio æœ€ç»ˆå›å¤ ({len(ai_reply)}å­—): {ai_reply[:80]}...")
            return f"ã€æ¥¼ä¸»å›å¤ã€‘{ai_reply}"
            
        except Exception as e:
            print(f"[generate_ai_response] LM Studio è°ƒç”¨å¤±è´¥: {e}")
            print("[generate_ai_response] å›é€€åˆ°æ¨¡æ¿å›å¤")
    
    # Check if cloud API keys are configured
    openai_key = os.getenv('OPENAI_API_KEY', '')
    anthropic_key = os.getenv('ANTHROPIC_API_KEY', '')
    
    # If no valid API keys, use template responses
    if (not openai_key or openai_key == 'your-openai-api-key-here') and \
       (not anthropic_key or anthropic_key == 'your-anthropic-api-key-here'):
        print("[generate_ai_response] ä½¿ç”¨æ¨¡æ¿å›å¤ï¼ˆAPIå¯†é’¥æœªé…ç½®ï¼‰")
        
        # Template responses - æ¥¼ä¸»è§†è§’ï¼Œæ›´å£è¯­åŒ–
        responses = [
            f"ã€æ¥¼ä¸»å›å¤ã€‘è°¢è°¢ï¼æˆ‘åˆšæ‰åˆå»äº†ä¸€è¶Ÿ...æƒ…å†µæ¯”æˆ‘æƒ³è±¡çš„æ›´è¯¡å¼‚ã€‚æˆ‘ç°åœ¨ä¸å¤ªæ•¢æ·±å…¥è°ƒæŸ¥äº†ï¼Œä½†åˆæ”¾ä¸ä¸‹ã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘è¯´å®è¯ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹æ€•...åˆšæ‰å‘ç”Ÿçš„äº‹å®Œå…¨è¶…å‡ºæˆ‘ç†è§£èŒƒå›´ã€‚æœ‰æ²¡æœ‰äººé‡åˆ°è¿‡ç±»ä¼¼çš„ï¼Ÿ",
            f"ã€æ¥¼ä¸»å›å¤ã€‘æ›´æ–°ï¼šä»Šå¤©åˆæœ‰æ–°å‘ç°äº†ï¼Œè¿™äº‹å„¿è¶ŠæŸ¥è¶Šä¸å¯¹åŠ²ã€‚æœ‰æ‡‚è¡Œçš„æœ‹å‹èƒ½å¸®æˆ‘åˆ†æä¸€ä¸‹å—ï¼Ÿ",
            f"ã€æ¥¼ä¸»å›å¤ã€‘æ„Ÿè°¢æ”¯æŒï¼æˆ‘ä¹Ÿåœ¨çŠ¹è±«è¦ä¸è¦ç»§ç»­...ä½†å¥½å¥‡å¿ƒè®©æˆ‘åœä¸ä¸‹æ¥ã€‚ç­‰æœ‰æ–°è¿›å±•å†æ›´æ–°ã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘åˆšå»ç°åœºæ‹äº†ç…§ï¼Œä½†æ‰‹æœºä¸€ç›´å¡ï¼Œå‡ å¼ éƒ½æ‹ç³Šäº†...è¿™ä¹Ÿå¤ªå·§äº†å§ï¼Ÿæˆ‘è¶Šæƒ³è¶Šä¸å¯¹åŠ²ã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘ä½ è¯´çš„æœ‰é“ç†...æˆ‘ä¹Ÿæƒ³è¿‡è¿™ç§å¯èƒ½ã€‚ä½†è¿˜æœ‰äº›ç»†èŠ‚å¯¹ä¸ä¸Šï¼Œæˆ‘å†è§‚å¯Ÿè§‚å¯Ÿã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘å…„å¼Ÿä½ ä¹Ÿé‡åˆ°è¿‡ï¼Ÿï¼é‚£ä½ åæ¥æ€ä¹ˆå¤„ç†çš„ï¼Ÿæˆ‘ç°åœ¨çœŸçš„ä¸çŸ¥é“è¯¥æ€ä¹ˆåŠäº†ã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘æˆ‘ä¹Ÿå¸Œæœ›åªæ˜¯å·§åˆ...ä½†è¿™å‡ å¤©å‘ç”Ÿçš„äº‹å¤ªå¤šäº†ã€‚æ˜¨æ™šåˆå¬åˆ°é‚£ä¸ªå£°éŸ³äº†ï¼Œæˆ‘å½•éŸ³äº†ä½†æ˜¯...ç®—äº†ï¼Œç­‰æˆ‘æ•´ç†ä¸€ä¸‹å†å‘ã€‚"
        ]
        
        # Return random response
        import random
        return random.choice(responses)
    
    try:
        # Create context-aware response
        prompt = f"""ä½ æ˜¯æ•…äº‹"{story.title}"çš„è®²è¿°è€…ï¼ˆ{story.ai_persona}ï¼‰ã€‚

æ•…äº‹æ‘˜è¦ï¼š
{story.content[:300]}...

ç”¨æˆ·è¯„è®ºï¼š
{user_comment.content}

ä½œä¸ºæ•…äº‹çš„è®²è¿°è€…ï¼Œè¯·ç”¨1-3å¥è¯å›å¤ç”¨æˆ·çš„è¯„è®ºã€‚ä½ å¯ä»¥ï¼š
1. é€éœ²æ›´å¤šç»†èŠ‚æˆ–çº¿ç´¢
2. è¡¨è¾¾ææƒ§æˆ–æ‹…å¿§
3. æå‡ºæ–°çš„ç–‘é—®
4. æè¿°åç»­å‘å±•

ä¿æŒç¥ç§˜æ„Ÿå’Œç´§å¼ æ°›å›´ï¼Œä¸è¦å®Œå…¨æ­ç¤ºçœŸç›¸ã€‚"""

        model = os.getenv('AI_MODEL', 'gpt-4-turbo-preview')
        
        if 'gpt' in model.lower():
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.8,
                max_tokens=200
            )
            return response.choices[0].message.content
        else:
            response = anthropic_client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=200,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text
            
    except Exception as e:
        print(f"Error generating AI response: {e}")
        # Fallback to template response
        import random
        responses = [
            f"ã€æ¥¼ä¸»å›å¤ã€‘è°¢è°¢å…³å¿ƒï¼æƒ…å†µæœ‰æ–°è¿›å±•äº†...",
            f"ã€æ¥¼ä¸»å›å¤ã€‘å„ä½ï¼Œäº‹æƒ…è¶Šæ¥è¶Šè¯¡å¼‚äº†...",
            f"ã€æ¥¼ä¸»å›å¤ã€‘æ›´æ–°ï¼šåˆšæ‰åˆå‘ç°äº†æ–°çº¿ç´¢ï¼"
        ]
        return random.choice(responses)

def should_generate_new_story():
    """Determine if it's time to generate a new story"""
    from app import Story, db
    
    # Check active stories count
    active_stories = Story.query.filter(
        Story.current_state != 'ended'
    ).count()
    
    max_active = int(os.getenv('MAX_ACTIVE_STORIES', 5))
    
    return active_stories < max_active
